{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Adding encoded metadata to the MMR edges\n",
    "We first need to encode the information of the period. We could add *strings* as metadata, but using integers would again be beneficial in terms of performance. The CSV file storing the periods encoding produced by the below cell will be named `period_encoding.csv`.\n",
    "## 1.1 Encoding the period values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_encoding_header = Array{String,1}([\"period\",\"encoding\"])\n",
    "period_encoding_filename = String(\"../data/period_encoding.csv\")\n",
    "\n",
    "open(period_encoding_filename, \"w\") do io\n",
    "    # Write CSV header\n",
    "    write(io, join(period_encoding_header, \",\") * \"\\n\")\n",
    "    for (index, period) in enumerate(readdir(String(\"../data/mmr_graph\")))\n",
    "        write(io, join([period,index-1],\",\") * \"\\n\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# Read period encoding as a dictionary\n",
    "period_encoding_dict = Dict{String,Int8}()\n",
    "open(period_encoding_filename) do io\n",
    "    for line in eachline(io)\n",
    "        if !occursin(line, join(period_encoding_header, \",\"))\n",
    "            period, encoding = split(line, \",\")\n",
    "            period_encoding_dict[period] = parse(Int8, encoding)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute period by line number in the dataset\n",
    "Instead of re-running the whole original encoding script in Python and add the period information for each line of the `mmr_encoded.csv` file, I may have a hashtable storing which are the *starting and ending lines* of each period, so that I can quickly create a duplicate of the `mmr_encoded.csv` data file that has the additional info. Of course this is possible because the merged file `mmr_encoded.csv` has been generated by respecting the chronological ordering of the period folders. The end result of the function `compute_periods_lines(...)` below is a hashtable of type `Dict{K,V}` where $K=period_{enc}$ and $V=[line_{start},line_{end})$, so that $line$ is the line number in the full MMR dataset when all parts are merged in a single file, as it happens with `mmr_encoded.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_periods_lines (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_periods_lines(dataset_dir::String)::Dict{Int8, Array{Int64, 1}}\n",
    "    periods_by_line_dict = Dict{Int8, Array{Int64, 1}}()\n",
    "    current_line_count = Int64(0)\n",
    "    for folder in readdir(dataset_dir)\n",
    "        period_enc = period_encoding_dict[folder]\n",
    "        folder_path = joinpath(dataset_dir, folder)\n",
    "        if !haskey(periods_by_line_dict, period_enc)\n",
    "            periods_by_line_dict[period_enc] = Array{Int64, 1}()\n",
    "        end\n",
    "        push!(periods_by_line_dict[period_enc], current_line_count)\n",
    "        for part in readdir(folder_path)\n",
    "            part_path = joinpath(folder_path, part)\n",
    "            if isfile(part_path) && startswith(part, \"part\")\n",
    "                open(part_path) do part_file\n",
    "                    for line in eachline(part_file)\n",
    "                        current_line_count += 1\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        push!(periods_by_line_dict[period_enc], current_line_count)\n",
    "    end\n",
    "    return periods_by_line_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48.621911 seconds (1.84 G allocations: 50.416 GiB, 6.43% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Int8,Array{Int64,1}} with 13 entries:\n",
       "  2  => [143085317, 201659109]\n",
       "  11 => [535041137, 575743666]\n",
       "  0  => [0, 75459299]\n",
       "  7  => [366285189, 412736805]\n",
       "  9  => [453080927, 493968535]\n",
       "  10 => [493968535, 535041137]\n",
       "  8  => [412736805, 453080927]\n",
       "  6  => [322066905, 366285189]\n",
       "  4  => [249380863, 287502444]\n",
       "  3  => [201659109, 249380863]\n",
       "  5  => [287502444, 322066905]\n",
       "  12 => [575743666, 612497446]\n",
       "  1  => [75459299, 143085317]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define variables\n",
    "dataset_dir = String(\"../data/mmr_graph\")\n",
    "\n",
    "@time periods_by_line_dict = compute_periods_lines(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Add period information to each line\n",
    "Now we can just iterate over the lines of the `mmr_encoded.csv` file and append the encoded period, by looking up the value to append in the just created `periods_by_line_dict`. The new file will be called `mmr_encoded_with_period.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_mmr_with_period (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_enc_period_by_line(periods_by_line_dict::Dict{Int8,Array{Int64,1}}, current_line_count::Int64)::Int8\n",
    "    local period_enc\n",
    "    for key in keys(periods_by_line_dict)\n",
    "        if current_line_count >= periods_by_line_dict[key][1] && current_line_count < periods_by_line_dict[key][2]\n",
    "            period_enc = key\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    return period_enc\n",
    "end\n",
    "\n",
    "function create_mmr_with_period(periods_by_line_dict::Dict{Int8,Array{Int64,1}}, mmr_enc_with_period_fn::String, mmr_enc_fn::String)\n",
    "    current_line_count = Int64(0)\n",
    "    local period_enc\n",
    "    open(mmr_enc_fn) do input\n",
    "        open(mmr_enc_with_period_fn, \"w\") do output\n",
    "            for line in eachline(input)\n",
    "                period_enc = get_enc_period_by_line(periods_by_line_dict, current_line_count)\n",
    "                new_line = join([line, string(period_enc)], \",\")\n",
    "                write(output, new_line * \"\\n\")\n",
    "                current_line_count +=1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563.598310 seconds (8.58 G allocations: 358.149 GiB, 5.05% gc time)\n"
     ]
    }
   ],
   "source": [
    "mmr_enc_with_period_fn = String(\"../data/mmr_encoded_with_period.csv\")\n",
    "mmr_enc_fn = String(\"../data/mmr_encoded.csv\")\n",
    "\n",
    "@time create_mmr_with_period(periods_by_line_dict, mmr_enc_with_period_fn, mmr_enc_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Generating final MMR dataset file\n",
    "After the period has been added as encoded information to each individual line in the dataset file, I can now generate the desired final version of the MMR datafile where each $(n_1,n_2)$ entry has the additional `periods` value as an **array of integers**, such that duplicate relationship entries are also removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dump_mmr_to_file (generic function with 1 method)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function split_line(line::String)\n",
    "    n1, n2, value = split(line, \",\")\n",
    "    key = join([n1, n2], \",\")\n",
    "    value = parse(Int8, value)\n",
    "    return key, value\n",
    "end\n",
    "\n",
    "function compute_edge_periods(mmr_enc_with_period_fn::String)::Dict{String,AbstractArray{Int8,1}}\n",
    "    edge_periods_dict = Dict{String,AbstractArray{Int8,1}}()\n",
    "    lines = Int64(0)\n",
    "    open(mmr_enc_with_period_fn) do input\n",
    "        for line in eachline(input)\n",
    "            if lines % 50000000 == 0 && lines != 0\n",
    "                @printf \"Processed %d lines...\\n\" lines\n",
    "            end\n",
    "            key, value = split_line(line)\n",
    "            if !haskey(edge_periods_dict, key)\n",
    "                edge_periods_dict[key] = Array{Int8,1}()\n",
    "            end\n",
    "            push!(edge_periods_dict[key], value)\n",
    "            lines += 1\n",
    "            flush(STDOUT)\n",
    "        end\n",
    "    end\n",
    "    println(\"Done!\")\n",
    "    return edge_periods_dict\n",
    "end\n",
    "\n",
    "function dump_mmr_to_file(mmr_final_filename::String, edge_periods_dict::Dict{String,AbstractArray{Int8,1}})\n",
    "    println(\"Dumping final MMR to file...\")\n",
    "    open(mmr_final_filename, \"w\") do output\n",
    "        for key in keys(edge_periods_dict)\n",
    "            write(output, join([key, join(edge_periods_dict[key], \",\")], \",\") * \"\\n\")\n",
    "        end\n",
    "    end\n",
    "    println(\"Done!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50000000 lines...\n",
      "Processed 100000000 lines...\n",
      "Processed 150000000 lines...\n",
      "Processed "
     ]
    }
   ],
   "source": [
    "mmr_final_filename = String(\"../data/mmr_encoded_final.csv\")\n",
    "\n",
    "@time edge_periods_dict = compute_edge_periods(mmr_enc_with_period_fn)\n",
    "@time dump_mmr_to_file(mmr_final_filename, edge_periods_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've included the code from the cells above in a separate `compute_compact_mmr.jl` script and let it run overnight. Timing stats at the end of the script showed that a peak of **90GB of consumed RAM** was reached and the overall execution time was **~18 hours**. Without the hardware capabilities I've been provided with, executing this script would have required relying on a line-by-line approach, which would have contributed to significantly slow down the process even more.\n",
    "\n",
    "Counting the number of lines with the command `wc -l mmr_encoded_final.csv` returns **434.193.958**, which represents the *total number of unique mutual interactions between two distinct users*. 10 sample lines of the file are formatted as such:\n",
    "```\n",
    "162551,358055,0;1;2;3;4\n",
    "2522022,11479046,0\n",
    "6765991,37193347,2\n",
    "1925412,69668768,12\n",
    "30945323,21996213,1\n",
    "1929344,1758244,0;1;2;3\n",
    "14179682,4572078,0\n",
    "47426332,12183913,3\n",
    "44640010,44517870,3;4;5\n",
    "12932181,80621407,10;12\n",
    "```\n",
    "As it's clear from th example above, the CSV is now structured with *3 columns*:\n",
    "- The first two represent the **mutual interaction between two Twitter users** as a $(source, target)$ pair;\n",
    "- The third one is a list of semicolon-separated values that indicates **all the periods when the correspondent mutual interaction occurred**, with values ranging from 0 to 12.\n",
    "\n",
    "As a final validation check, let's show that such list of periods:\n",
    "- Has maximum length of 13;\n",
    "- Has unique values (e.g. it's not allowed to have more than a unique digit from 0 to 12 in the same list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50000000 lines...\n",
      "Processed 100000000 lines...\n",
      "Processed 150000000 lines...\n",
      "Processed 200000000 lines...\n",
      "Processed 250000000 lines...\n",
      "Processed 300000000 lines...\n",
      "Processed 350000000 lines...\n",
      "Processed 400000000 lines...\n",
      "Done! Found 0 issues.\n",
      "503.230951 seconds (9.77 G allocations: 453.569 GiB, 13.03% gc time)\n"
     ]
    }
   ],
   "source": [
    "function validate_entry(entry::String, current_line::Int64)::Int64\n",
    "    issues = Int64(0)\n",
    "    # Condition (1): max length 13\n",
    "    periods_array = map(x -> parse(Int8, x), split(split(entry, \",\")[3], \";\"))\n",
    "    if length(periods_array) > 13\n",
    "        println(\"Found periods array with more than the maximum allowed number of values (13) at line $current_line: $entry\")\n",
    "        issues += 1\n",
    "    end\n",
    "    \n",
    "    # Condition (2): All values should be unique\n",
    "    if length(periods_array) != length(Set{Int8}(periods_array))\n",
    "        println(\"Found periods array with non unique values at line $current_line: $entry\")\n",
    "        issues += 1\n",
    "    end\n",
    "    \n",
    "    return issues\n",
    "end\n",
    "\n",
    "function find_issues()\n",
    "   mmr_final_filename = String(\"../data/mmr_encoded_final.csv\")\n",
    "    open(mmr_final_filename) do io\n",
    "        counter = Int64(0)\n",
    "        issues = Int64(0)\n",
    "        for line in eachline(io)\n",
    "            issues += validate_entry(line, counter)\n",
    "            counter +=1\n",
    "            if counter % 50000000 == 0\n",
    "                println(\"Processed $counter lines...\")\n",
    "            end\n",
    "        end\n",
    "        println(\"Done! Found $issues issues.\")\n",
    "    end\n",
    "end\n",
    "\n",
    "@time find_issues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results show that the final dataset file is properly formatted without unexpected errors. As a final chapter consideration, I'm now ready to re-import the dataset in Neo4j and see how the new network would look like after applying the optimizations as described in this notebook.\n",
    "\n",
    "Hereby a **summary of the core improvements** as a result of the optimization process:\n",
    "\n",
    "| Dataset Feature | Old | New |\n",
    "|---|---|---|\n",
    "| Total Relationships | 612.497.446 (~600M) | 434.193.958 (~400M) |\n",
    "| File Size (GB) | 9.8 | 8.3 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
