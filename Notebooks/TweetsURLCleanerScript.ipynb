{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets URL Cleaner\n",
    "Use this notebook to clean tweet files that have been created before the correct implementation of the URL cleaner was applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "tweets_dir = \"../lib/GetOldTweets-python/out/completed\"\n",
    "excluded = [\"ipynb_checkpoints\"]\n",
    "\n",
    "def read_large_file(file_object):\n",
    "    while True:\n",
    "        data = file_object.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        yield data.rstrip('\\n')\n",
    "\n",
    "def remove_urls_from_text(text):\n",
    "    patterns = [r'pic\\.twitter\\.com/\\S*', r'https?://\\S*']\n",
    "    for p in patterns:\n",
    "        text = re.sub(p, \"\", text).strip()\n",
    "    return text\n",
    "\n",
    "def should_skip(name):\n",
    "    skip = False\n",
    "    for el in excluded:\n",
    "        if el in name:\n",
    "            skip = True\n",
    "            break\n",
    "    return skip\n",
    "        \n",
    "# Clean hashtags file by removing additional URLs from tweet text\n",
    "def clean_tweets():\n",
    "    for tweets_filename in os.listdir(tweets_dir):\n",
    "        if should_skip(tweets_filename):\n",
    "            continue\n",
    "        input_filepath = os.path.join(tweets_dir,tweets_filename)\n",
    "        output_filepath = os.path.join(tweets_dir,os.path.splitext(tweets_filename)[0]+\"_cleaned.json\")\n",
    "        print(\"\\n%s\" %tweets_filename)\n",
    "        print(\"Occurrences of pattern 'pic\\.twitter\\.com/\\S*':\")\n",
    "        !egrep \"pic\\.twitter\\.com/\\S*\" $input_filepath | wc -l\n",
    "        print(\"Occurrences of pattern 'https?://\\S*':\")\n",
    "        !egrep \"https?://\\S*\" $input_filepath | wc -l\n",
    "        with open(output_filepath, \"w\") as fout:\n",
    "            with open(input_filepath) as fin:\n",
    "                for line in read_large_file(fin):\n",
    "                    tweet = json.loads(line)\n",
    "                    tweet[\"text\"] = remove_urls_from_text(tweet[\"text\"])\n",
    "                    if \"quoted_status\" in tweet:\n",
    "                        tweet[\"quoted_status\"][\"text\"] = remove_urls_from_text(tweet[\"quoted_status\"][\"text\"])\n",
    "                    if \"retweeted_status\" in tweet:\n",
    "                        tweet[\"retweeted_status\"][\"text\"] = remove_urls_from_text(tweet[\"retweeted_status\"][\"text\"])\n",
    "                    newLine = json.dumps(tweet)\n",
    "                    fout.write(newLine+\"\\n\")\n",
    "        print(\"Post-cleanup check:\")\n",
    "        print(\"Occurrences of pattern 'pic\\.twitter\\.com/\\S*':\")\n",
    "        !egrep \"pic\\.twitter\\.com/\\S*\" $output_filepath | wc -l\n",
    "        print(\"Occurrences of pattern 'https?://\\S*':\")\n",
    "        !egrep \"https?://\\S*\" $output_filepath | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
