{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Windows keystroke for \\` character is ALT+96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import networkx as nx\n",
    "import operator\n",
    "import json\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Settings\n",
    "dataset_dir = \"../mmr_graph/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Storing Twitter usernames without any transformation in memory would mean wasting loads of memory to store a relatively expensive data type such as strings. I could optimize this by performing some *data encoding* on the user-names and convert strings to integers by keeping a 1:1 mapping between the string representation of the username and its integer representation. This would result in huge memory optimization prior to loading the graph into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Usernames Encoding and Full Network\n",
    "The below code portions process all the data files from the MMR dataset and iteratively add edges to the undirected graph. The end result of the execution are two files: `usernames.json` containing a JSON with string username-integer username as key-value pairs, and `mmr.adjlist` which contains the graph representation that can be easily loaded again in memory without processing again all the dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support functions declarations\n",
    "def add_new_user(username):\n",
    "    global current_user_id\n",
    "    global unique_usernames_encoding\n",
    "    if not username in unique_usernames_encoding:\n",
    "        unique_usernames_encoding[username] = current_user_id\n",
    "        current_user_id += 1\n",
    "        if current_user_id%10000000 == 0:\n",
    "            print(\"Currently processed {0} usernames\".format(current_user_id))\n",
    "\n",
    "def get_encoding(username):\n",
    "    global unique_usernames_encoding\n",
    "    return unique_usernames_encoding[username]\n",
    "\n",
    "def process_line(line):\n",
    "    a,b = line.strip(\"()\\n\").split(', ')\n",
    "    a = a.strip(\"u'\")\n",
    "    b = b.strip(\"u'\")\n",
    "    add_new_user(a)\n",
    "    add_new_user(b)\n",
    "    a_enc = get_encoding(a)\n",
    "    b_enc = get_encoding(b)\n",
    "    return a_enc, b_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files in folder 2016-03\n",
      "Currently processed 10000000 usernames\n",
      "Currently processed 10000000 usernames\n",
      "Currently processed 10000000 usernames\n",
      "Currently processed 10000000 usernames\n",
      "Processing files in folder 2016-09\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n",
      "Currently processed 20000000 usernames\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5c0437063cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0ma_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_new_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"u'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mb_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_new_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"u'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processed all usernames. Total unique usernames: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_user_id\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, u_of_edge, v_of_edge, **attr)\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;31m# add the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m         \u001b[0mdatadict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mdatadict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start processing\n",
    "unique_usernames_encoding = {}\n",
    "current_user_id = 0 #Start with ID = 0\n",
    "\n",
    "# Dynamically add edges to graph\n",
    "G = nx.Graph()\n",
    "for folder in os.listdir(dataset_dir):\n",
    "    folder_path = os.path.join(dataset_dir, folder)\n",
    "    print(\"Processing files in folder {0}\".format(folder))\n",
    "    for part in os.listdir(folder_path):\n",
    "        part_path = os.path.join(folder_path, part)\n",
    "        if os.path.isfile(part_path) and part.startswith(\"part\"):\n",
    "            with open(part_path, encoding=\"utf-8\") as part:\n",
    "                for line in part:\n",
    "                    a_enc, b_enc = process_line(line)\n",
    "                    G.add_edge(a_enc, b_enc)\n",
    "print(\"Processed all usernames. Total unique usernames: {0}\".format(current_user_id-1))\n",
    "           \n",
    "# Save usernames to file\n",
    "output_filename = \"usernames.json\"\n",
    "print(\"Saving usernames to {0}...\".format(output_filename))\n",
    "with open(output_filename, \"w\") as usernames_file:\n",
    "    json.dump(unique_usernames_encoding, usernames_file)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Save graph to file to easily import again\n",
    "nx.write_adjlist(G, \"mmr.adjlist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Main Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-8087fc244e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbetweenness_centrality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetweenness_centrality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/networkx/algorithms/centrality/betweenness.py\u001b[0m in \u001b[0;36mbetweenness_centrality\u001b[0;34m(G, k, normalized, weight, endpoints, seed)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# single source shortest paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use BFS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_source_shortest_path_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use Dijkstra's algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_source_dijkstra_path_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/networkx/algorithms/centrality/betweenness.py\u001b[0m in \u001b[0;36m_single_source_shortest_path_basic\u001b[0;34m(G, s)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# use BFS to find shortest paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mDv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "betweenness_centrality = networkx.betweenness_centrality(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('brucevh', 2.0507457024060374e-08),\n",
       " ('eceyorenc', 2.0507457024060374e-08),\n",
       " ('bcci', 2.0507457024060374e-08),\n",
       " ('rongieprk', 2.0507457024060374e-08),\n",
       " ('tifayneh', 2.0507457024060374e-08),\n",
       " ('derbyyyy', 2.0507457024060374e-08),\n",
       " ('nesaazzahra', 2.0507457024060374e-08),\n",
       " ('kemova99', 2.0507457024060374e-08),\n",
       " ('psychdatageek', 2.0507457024060374e-08)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in sorted(betweenness_centrality.items(), key=operator.itemgetter(1), reverse=True) if x[1] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
